name: Deploy Backend, Worker, and Redis Cache

on:
  push:
    branches:
      - main
      - features/pipeline_backend
    paths:
      - 'backend/**'
      - '.github/workflows/backend-deploy.yml'
  workflow_dispatch:
    inputs:
      stage:
        description: 'Deployment stage (dev/staging/prod)'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - prod

env:
  AWS_REGION: ${{ vars.AWS_REGION || 'ap-southeast-1' }}
  STAGE: ${{ inputs.stage || 'dev' }}
  NODE_VERSION: '24'
  PYTHON_VERSION: '3.12'

jobs:
  # Run Database Migrations
  run-migrations:
    name: Run Database Migrations
    runs-on: ubuntu-latest
    environment: ${{ inputs.stage || 'dev' }}
    if: false  # Temporarily disabled
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Get database connection details
        id: get-db
        run: |
          STAGE="${{ env.STAGE }}"
          # RDS instance identifier: "${stage}-flowgenie-db" (e.g., "dev-flowgenie-db")
          DB_IDENTIFIER="${STAGE}-flowgenie-db"
          
          echo "Getting database connection details for RDS instance: $DB_IDENTIFIER"
          echo "Note: This is the RDS instance identifier. The PostgreSQL database name may differ."
          
          # Get RDS endpoint
          RDS_ENDPOINT=$(aws rds describe-db-instances \
            --db-instance-identifier "$DB_IDENTIFIER" \
            --query 'DBInstances[0].Endpoint.Address' \
            --output text 2>/dev/null || echo "")
          
          if [ -z "$RDS_ENDPOINT" ] || [ "$RDS_ENDPOINT" == "None" ]; then
            echo "ERROR: RDS instance '$DB_IDENTIFIER' not found"
            echo "Please ensure the database is deployed via Terraform"
            exit 1
          fi
          
          # Get database name and username (from RDS instance)
          DB_NAME=$(aws rds describe-db-instances \
            --db-instance-identifier "$DB_IDENTIFIER" \
            --query 'DBInstances[0].DBName' \
            --output text 2>/dev/null || echo "")
          
          if [ -z "$DB_NAME" ] || [ "$DB_NAME" == "None" ]; then
            echo "ERROR: Could not retrieve database name from RDS instance '$DB_IDENTIFIER'"
            echo "Please ensure the RDS instance exists and has a database name configured"
            exit 1
          fi
          
          DB_USERNAME=$(aws rds describe-db-instances \
            --db-instance-identifier "$DB_IDENTIFIER" \
            --query 'DBInstances[0].MasterUsername' \
            --output text 2>/dev/null || echo "")
          
          if [ -z "$DB_USERNAME" ] || [ "$DB_USERNAME" == "None" ]; then
            echo "ERROR: Could not retrieve database username from RDS instance '$DB_IDENTIFIER'"
            echo "Please ensure the RDS instance exists and has a master username configured"
            exit 1
          fi
          
          # Determine secret name based on stage
          if [ "$STAGE" == "prod" ]; then
            DB_SECRET_NAME="DB_PASSWORD_PROD"
          elif [ "$STAGE" == "staging" ]; then
            DB_SECRET_NAME="DB_PASSWORD_STAGING"
          else
            DB_SECRET_NAME="DB_PASSWORD_DEV"
          fi
          
          echo "rds_endpoint=$RDS_ENDPOINT" >> $GITHUB_OUTPUT
          echo "db_name=$DB_NAME" >> $GITHUB_OUTPUT
          echo "db_username=$DB_USERNAME" >> $GITHUB_OUTPUT
          echo "db_secret_name=$DB_SECRET_NAME" >> $GITHUB_OUTPUT
          
          echo "RDS Instance Identifier: $DB_IDENTIFIER"
          echo "Database endpoint: $RDS_ENDPOINT"
          echo "PostgreSQL Database Name: $DB_NAME"
          echo "Database username: $DB_USERNAME"
          echo "Database secret name: $DB_SECRET_NAME"
          
          # Verify database name is retrieved
          echo ""
          echo "âœ… Successfully retrieved database connection details:"
          echo "   Instance: $DB_IDENTIFIER"
          echo "   PostgreSQL DB: $DB_NAME"
          echo "   Username: $DB_USERNAME"
          echo "   Endpoint: $RDS_ENDPOINT"

      - name: Run database migrations via ECS
        id: run-migrations
        env:
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
        run: |
          if ! command -v jq &> /dev/null; then
            sudo apt-get update && sudo apt-get install -y jq
          fi
          
          STAGE="${{ env.STAGE }}"
          CLUSTER_NAME="${STAGE}-flowgenie-worker"
          TASK_DEFINITION="${STAGE}-flowgenie-worker"
          
          # Construct DATABASE_URL
          DATABASE_URL="postgresql://${{ steps.get-db.outputs.db_username }}:${DB_PASSWORD}@${{ steps.get-db.outputs.rds_endpoint }}:5432/${{ steps.get-db.outputs.db_name }}"
          
          # Get network configuration from ECS service
          SERVICE_NAME="${STAGE}-flowgenie-worker"
          NETWORK_CONFIG=$(aws ecs describe-services \
            --cluster "$CLUSTER_NAME" \
            --services "$SERVICE_NAME" \
            --query 'services[0].networkConfiguration.awsvpcConfiguration' \
            --output json 2>/dev/null || echo "{}")
          
          if [ "$NETWORK_CONFIG" != "{}" ] && [ "$NETWORK_CONFIG" != "null" ]; then
            SUBNET_IDS=$(echo "$NETWORK_CONFIG" | jq -r '.subnets[]' | jq -R -s -c 'split("\n") | map(select(length > 0))')
            SECURITY_GROUP_IDS=$(echo "$NETWORK_CONFIG" | jq -r '.securityGroups[]' | jq -R -s -c 'split("\n") | map(select(length > 0))')
          else
            echo "ERROR: Could not get network configuration from ECS service"
            exit 1
          fi
          
          # Create network configuration JSON
          NETWORK_CONFIG_JSON=$(jq -n \
            --argjson subnets "$SUBNET_IDS" \
            --argjson securityGroups "$SECURITY_GROUP_IDS" \
            '{
              awsvpcConfiguration: {
                subnets: $subnets,
                securityGroups: $securityGroups,
                assignPublicIp: "DISABLED"
              }
            }')
          
          # Run migrations
          echo "Running database migrations..."
          MIGRATION_OVERRIDES_JSON=$(jq -n \
            --arg container_name "worker" \
            --arg db_url "$DATABASE_URL" \
            --arg stage "$STAGE" \
            '{
              containerOverrides: [{
                name: $container_name,
                command: ["sh", "-c", "cd /app && npx prisma migrate deploy"],
                environment: [
                  {name: "DATABASE_URL", value: $db_url},
                  {name: "STAGE", value: $stage},
                  {name: "NODE_ENV", value: "production"}
                ]
              }]
            }')
          
          TASK_ARN=$(aws ecs run-task \
            --cluster "$CLUSTER_NAME" \
            --task-definition "$TASK_DEFINITION" \
            --launch-type FARGATE \
            --network-configuration "$NETWORK_CONFIG_JSON" \
            --overrides "$MIGRATION_OVERRIDES_JSON" \
            --query 'tasks[0].taskArn' \
            --output text)
          
          if [ -z "$TASK_ARN" ] || [ "$TASK_ARN" == "None" ]; then
            echo "ERROR: Failed to start migration task"
            exit 1
          fi
          
          echo "Migration task started: $TASK_ARN"
          echo "Waiting for completion..."
          
          # Wait for task to complete
          MAX_WAIT=600
          ELAPSED=0
          while [ $ELAPSED -lt $MAX_WAIT ]; do
            TASK_STATUS=$(aws ecs describe-tasks \
              --cluster "$CLUSTER_NAME" \
              --tasks "$TASK_ARN" \
              --query 'tasks[0].lastStatus' \
              --output text 2>/dev/null || echo "UNKNOWN")
            
            if [ "$TASK_STATUS" == "STOPPED" ]; then
              break
            fi
            sleep 5
            ELAPSED=$((ELAPSED + 5))
          done
          
          # Get exit code
          EXIT_CODE=$(aws ecs describe-tasks \
            --cluster "$CLUSTER_NAME" \
            --tasks "$TASK_ARN" \
            --query 'tasks[0].containers[0].exitCode' \
            --output text 2>/dev/null || echo "null")
          
          # Get logs
          LOG_GROUP="/ecs/${STAGE}-flowgenie-worker"
          TASK_ID=$(echo "$TASK_ARN" | awk -F'/' '{print $3}')
          LOG_STREAM="ecs/worker/$TASK_ID"
          aws logs tail "$LOG_GROUP" --log-stream-names "$LOG_STREAM" --format short --since 10m 2>/dev/null | tail -50 || echo "Could not fetch logs"
          
          if [ "$EXIT_CODE" != "0" ] && [ "$EXIT_CODE" != "null" ]; then
            echo "ERROR: Migration failed with exit code: $EXIT_CODE"
            exit 1
          fi
          
          echo "âœ… Database migrations completed successfully"

  # Deploy Lambda Backend
  deploy-lambda:
    name: Deploy Lambda Backend
    runs-on: ubuntu-latest
    environment: ${{ inputs.stage || 'dev' }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: backend/package-lock.json

      - name: Install backend dependencies
        working-directory: ./backend
        run: |
          echo "Installing backend dependencies..."
          npm ci
          echo "Dependencies installed successfully"

      - name: Build backend
        working-directory: ./backend
        env:
          NODE_ENV: production
        run: |
          echo "Building backend application..."
          npm run build
          
          if [ ! -d "dist" ] || [ -z "$(ls -A dist)" ]; then
            echo "ERROR: Build completed but dist folder is empty or missing"
            exit 1
          fi
          
          # Verify main.js is built (NestJS builds to dist/src/)
          if [ ! -f "dist/src/main.js" ]; then
            echo "ERROR: main.js not found in dist/src/ after build"
            echo "Checking what files were built:"
            find dist -name "*.js" -type f | head -20
            exit 1
          fi
          
          echo "âœ… Build completed successfully"
          echo "âœ… main.js found in dist/src/"
          ls -lh dist/src/main.js

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Get ECR repository URI
        id: ecr-repo
        run: |
          STAGE="${{ env.STAGE }}"
          REPO_NAME="${STAGE}-flowgenie-func"
          
          # Create ECR repository if it doesn't exist
          if ! aws ecr describe-repositories --repository-names "$REPO_NAME" --region ${{ env.AWS_REGION }} >/dev/null 2>&1; then
            echo "Creating ECR repository: $REPO_NAME"
            aws ecr create-repository \
              --repository-name "$REPO_NAME" \
              --region ${{ env.AWS_REGION }} \
              --image-scanning-configuration scanOnPush=true \
              --encryption-configuration encryptionType=AES256
          fi
          
          # Get repository URI
          REPO_URI=$(aws ecr describe-repositories \
            --repository-names "$REPO_NAME" \
            --region ${{ env.AWS_REGION }} \
            --query 'repositories[0].repositoryUri' \
            --output text)
          
          echo "ECR Repository: $REPO_URI"
          echo "ecr_repository=$REPO_URI" >> $GITHUB_ENV
          echo "ecr_repo_name=$REPO_NAME" >> $GITHUB_ENV

      - name: Build, tag, and push Docker image to Amazon ECR
        working-directory: ./backend
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ${{ env.ecr_repo_name }}
          IMAGE_TAG: ${{ github.sha }}
          GOOGLE_CLIENT_ID: ${{ vars.GOOGLE_CLIENT_ID }}
          GOOGLE_CLIENT_SECRET: ${{ secrets.GOOGLE_CLIENT_SECRET }}
          GOOGLE_REDIRECT_URI: ${{ vars.GOOGLE_REDIRECT_URI }}
        run: |
          echo "Building Docker image..."
          docker build \
            -f Dockerfile.lambda \
            --build-arg GOOGLE_CLIENT_ID="$GOOGLE_CLIENT_ID" \
            --build-arg GOOGLE_CLIENT_SECRET="$GOOGLE_CLIENT_SECRET" \
            --build-arg GOOGLE_REDIRECT_URI="$GOOGLE_REDIRECT_URI" \
            -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
          docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:latest
          
          echo "Pushing Docker image to ECR..."
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest
          
          echo "âœ… Docker image pushed successfully"
          echo "  Image: $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG"
          echo "ecr_image_uri=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" >> $GITHUB_ENV

      - name: Get Lambda function name
        id: get-lambda
        run: |
          FUNCTION_NAME="${{ env.STAGE }}-flowgenie-func"
          echo "lambda_function_name=$FUNCTION_NAME" >> $GITHUB_OUTPUT
          echo "Target Lambda function: $FUNCTION_NAME"

      - name: Update Lambda function to use container image
        run: |
          FUNCTION_NAME="${{ steps.get-lambda.outputs.lambda_function_name }}"
          IMAGE_URI="${{ env.ecr_image_uri }}"
          
          echo "Updating Lambda function to use container image..."
          
          # Check if function exists
          if ! aws lambda get-function --function-name "$FUNCTION_NAME" >/dev/null 2>&1; then
            echo "ERROR: Lambda function '$FUNCTION_NAME' does not exist"
            echo "Please run infrastructure deployment first (infra-deploy workflow)"
            exit 1
          fi
          
          # Check current package type
          CURRENT_PACKAGE_TYPE=$(aws lambda get-function \
            --function-name "$FUNCTION_NAME" \
            --region ${{ env.AWS_REGION }} \
            --query 'Configuration.PackageType' \
            --output text)
          
          echo "Current package type: $CURRENT_PACKAGE_TYPE"
          
          # If package type is Zip, update it to Image first
          if [ "$CURRENT_PACKAGE_TYPE" == "Zip" ]; then
            echo "Converting Lambda function from Zip to Image package type..."
            aws lambda update-function-configuration \
              --function-name "$FUNCTION_NAME" \
              --package-type Image \
              --image-uri "$IMAGE_URI" \
              --region ${{ env.AWS_REGION }}
            
            echo "Waiting for function configuration update..."
            aws lambda wait function-updated \
              --function-name "$FUNCTION_NAME" \
              --region ${{ env.AWS_REGION }}
            
            echo "âœ… Lambda function package type updated to Image"
          else
            # Update function code to use container image
            echo "Updating function code with new image..."
            aws lambda update-function-code \
              --function-name "$FUNCTION_NAME" \
              --image-uri "$IMAGE_URI" \
              --region ${{ env.AWS_REGION }}
          fi
          
          echo "âœ… Lambda function updated to use container image: $IMAGE_URI"

      - name: Wait for Lambda update
        run: |
          FUNCTION_NAME="${{ steps.get-lambda.outputs.lambda_function_name }}"
          
          echo "Waiting for Lambda function to be ready..."
          aws lambda wait function-updated \
            --function-name "$FUNCTION_NAME" \
            --region ${{ env.AWS_REGION }}
          
          echo "âœ… Lambda function is ready"

      - name: Update Lambda environment variables
        env:
          # Secrets from GitHub Secrets
          APP_URL: ${{ secrets.APP_URL }}
          AWS_DYNAMODB: ${{ secrets.AWS_DYNAMODB }}
          CORS_ORIGINS: ${{ secrets.CORS_ORIGINS }}
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DEVOPS_TOKEN: ${{ secrets.DEVOPS_TOKEN }}
          FRONTEND_URL: ${{ secrets.FRONTEND_URL }}
          GOOGLE_APPLICATION_CREDENTIALS: ${{ secrets.GOOGLE_APPLICATION_CREDENTIALS }}
          GOOGLE_CLIENT_SECRET: ${{ secrets.GOOGLE_CLIENT_SECRET }}
          GOOGLE_SERVICE_ACCOUNT: ${{ secrets.GOOGLE_SERVICE_ACCOUNT }}
          JWT_SECRET: ${{ secrets.JWT_SECRET }}
          REDIS_URL: ${{ secrets.REDIS_URL }}
          REDIS_AUTH_TOKEN: ${{ secrets.REDIS_AUTH_TOKEN }}
          REDIS_HOST: ${{ secrets.REDIS_HOST }}
          REDIS_PORT: ${{ secrets.REDIS_PORT }}
          # Variables from GitHub Variables
          AMPLIFY_BRANCH_NAME: ${{ vars.AMPLIFY_BRANCH_NAME }}
          AMPLIFY_DOMAIN: ${{ vars.AMPLIFY_DOMAIN }}
          AMPLIFY_REPOSITORY_URL: ${{ vars.AMPLIFY_REPOSITORY_URL }}
          BACKEND_ENVIRONMENT_VARIABLES: ${{ vars.BACKEND_ENVIRONMENT_VARIABLES }}
          DB_NAME: ${{ vars.DB_NAME }}
          DB_USERNAME: ${{ vars.DB_USERNAME }}
          ENABLE_SWAGGER: ${{ vars.ENABLE_SWAGGER }}
          FRONTEND_ENVIRONMENT_VARIABLES: ${{ vars.FRONTEND_ENVIRONMENT_VARIABLES }}
          GOOGLE_CLIENT_ID: ${{ vars.GOOGLE_CLIENT_ID }}
          GOOGLE_PROJECT_NAME: ${{ vars.GOOGLE_PROJECT_NAME }}
          GOOGLE_REDIRECT_URI: ${{ vars.GOOGLE_REDIRECT_URI }}
          JWT_EXPIRES_IN: ${{ vars.JWT_EXPIRES_IN }}
          REFRESH_TOKEN_EXPIRES_IN: ${{ vars.REFRESH_TOKEN_EXPIRES_IN }}
          STAGE_VAR: ${{ vars.STAGE }}
        run: |
          FUNCTION_NAME="${{ steps.get-lambda.outputs.lambda_function_name }}"
          STAGE="${{ env.STAGE }}"
          
          # Ensure jq is available
          if ! command -v jq &> /dev/null; then
            echo "jq is required but not installed. Installing..."
            sudo apt-get update && sudo apt-get install -y jq
          fi
          
          echo "Updating Lambda environment variables from GitHub Secrets and Variables..."
          
          # Get current Lambda function configuration
          LAMBDA_CONFIG=$(aws lambda get-function-configuration \
            --function-name "$FUNCTION_NAME" \
            --region ${{ env.AWS_REGION }} \
            --output json)
          
          CURRENT_ENV=$(echo "$LAMBDA_CONFIG" | jq -r '.Environment.Variables // {}')
          
          echo "Current Lambda environment variables:"
          echo "$CURRENT_ENV" | jq '.'
          
          # Start with current environment variables
          UPDATED_ENV=$(echo "$CURRENT_ENV" | jq -c '.')
          
          # List of all secrets to inject (from GitHub Secrets)
          SECRETS=(
            "APP_URL"
            "AWS_DYNAMODB"
            "CORS_ORIGINS"
            "DATABASE_URL"
            "DB_PASSWORD"
            "DEVOPS_TOKEN"
            "FRONTEND_URL"
            "GOOGLE_APPLICATION_CREDENTIALS"
            "GOOGLE_CLIENT_SECRET"
            "GOOGLE_SERVICE_ACCOUNT"
            "JWT_SECRET"
            "REDIS_URL"
            "REDIS_HOST"
            "REDIS_PORT"
            "REDIS_AUTH_TOKEN"
          )
          
          # List of all variables to inject (from GitHub Variables)
          # Note: AWS_REGION is excluded as it's a reserved Lambda environment variable
          VARIABLES=(
            "AMPLIFY_BRANCH_NAME"
            "AMPLIFY_DOMAIN"
            "AMPLIFY_REPOSITORY_URL"
            "BACKEND_ENVIRONMENT_VARIABLES"
            "DB_NAME"
            "DB_USERNAME"
            "ENABLE_SWAGGER"
            "FRONTEND_ENVIRONMENT_VARIABLES"
            "GOOGLE_CLIENT_ID"
            "GOOGLE_PROJECT_NAME"
            "GOOGLE_REDIRECT_URI"
            "JWT_EXPIRES_IN"
            "REFRESH_TOKEN_EXPIRES_IN"
            "STAGE"
          )
          
          # Inject secrets
          echo ""
          echo "ðŸ” Injecting secrets from GitHub Secrets..."
          for secret_name in "${SECRETS[@]}"; do
            # Get the value from environment (mapped from secrets)
            secret_value=$(eval echo \$$secret_name)
            
            if [ -n "$secret_value" ] && [ "$secret_value" != "" ]; then
              echo "  Setting $secret_name (masked)"
              UPDATED_ENV=$(echo "$UPDATED_ENV" | jq -c --arg key "$secret_name" --arg value "$secret_value" '. + {($key): $value}')
            else
              echo "  âš ï¸  $secret_name not set in GitHub Secrets, skipping"
            fi
          done
          
          # Inject variables
          echo ""
          echo "ðŸ“ Injecting variables from GitHub Variables..."
          for var_name in "${VARIABLES[@]}"; do
            # Handle special case: STAGE_VAR -> STAGE
            env_var_name="$var_name"
            if [ "$var_name" = "STAGE" ]; then
              env_var_name="STAGE_VAR"
            fi
            
            # Get the value from environment (mapped from vars)
            var_value=$(eval echo \$$env_var_name)
            
            if [ -n "$var_value" ] && [ "$var_value" != "" ]; then
              echo "  Setting $var_name = $var_value"
              UPDATED_ENV=$(echo "$UPDATED_ENV" | jq -c --arg key "$var_name" --arg value "$var_value" '. + {($key): $value}')
            else
              echo "  âš ï¸  $var_name not set in GitHub Variables, skipping"
            fi
          done
          
          # Set NODE_ENV based on STAGE if not already set
          if [ -z "$(echo "$UPDATED_ENV" | jq -r '.NODE_ENV // empty')" ]; then
            NODE_ENV_VALUE="production"
            if [ "$STAGE" != "prod" ]; then
              NODE_ENV_VALUE="$STAGE"
            fi
            echo "  Setting NODE_ENV=$NODE_ENV_VALUE"
            UPDATED_ENV=$(echo "$UPDATED_ENV" | jq -c --arg env "$NODE_ENV_VALUE" '. + {NODE_ENV: $env}')
          fi
          
          # Filter out reserved Lambda environment variables that cannot be modified
          echo ""
          echo "ðŸ” Filtering out reserved Lambda environment variables..."
          RESERVED_KEYS=(
            "AWS_LAMBDA_EXEC_WRAPPER"
            "AWS_EXECUTION_ENV"
            "AWS_LAMBDA_FUNCTION_NAME"
            "AWS_LAMBDA_FUNCTION_VERSION"
            "AWS_LAMBDA_FUNCTION_MEMORY_SIZE"
            "AWS_LAMBDA_LOG_GROUP_NAME"
            "AWS_LAMBDA_LOG_STREAM_NAME"
            "AWS_LAMBDA_RUNTIME_API"
            "AWS_REGION"
            "AWS_DEFAULT_REGION"
            "_AWS_XRAY_TRACING_NAME"
            "_X_AMZN_TRACE_ID"
            "LAMBDA_TASK_ROOT"
            "LAMBDA_RUNTIME_DIR"
            "_HANDLER"
            "PATH"
            "LD_LIBRARY_PATH"
            "TZ"
            "LANG"
          )
          
          # Remove reserved keys from UPDATED_ENV
          FILTERED_ENV=$(echo "$UPDATED_ENV" | jq -c '.')
          for reserved_key in "${RESERVED_KEYS[@]}"; do
            if echo "$FILTERED_ENV" | jq -e "has(\"$reserved_key\")" > /dev/null; then
              echo "  âš ï¸  Removing reserved key: $reserved_key"
              FILTERED_ENV=$(echo "$FILTERED_ENV" | jq -c "del(.\"$reserved_key\")")
            fi
          done
          
          UPDATED_ENV="$FILTERED_ENV"
          
          # Check if update is needed
          CURRENT_ENV_STR=$(echo "$CURRENT_ENV" | jq -c -S '.')
          UPDATED_ENV_STR=$(echo "$UPDATED_ENV" | jq -c -S '.')
          
          if [ "$CURRENT_ENV_STR" != "$UPDATED_ENV_STR" ]; then
            echo ""
            echo "Updating Lambda function environment variables..."
            
            # Create proper JSON structure for --environment parameter
            # Format: {"Variables": {...}}
            ENVIRONMENT_JSON=$(echo "$UPDATED_ENV" | jq -c '{Variables: .}')
            
            # Update Lambda function configuration
            aws lambda update-function-configuration \
              --function-name "$FUNCTION_NAME" \
              --environment "$ENVIRONMENT_JSON" \
              --region ${{ env.AWS_REGION }} > /dev/null
            
            echo "Waiting for Lambda function configuration update..."
            aws lambda wait function-updated \
              --function-name "$FUNCTION_NAME" \
              --region ${{ env.AWS_REGION }}
            
            echo "âœ… Lambda environment variables updated"
          else
            echo ""
            echo "âœ… All environment variables are already set correctly"
          fi
          
          # Display final environment variables (masked)
          echo ""
          echo "Final Lambda environment variables:"
          FINAL_ENV=$(aws lambda get-function-configuration \
            --function-name "$FUNCTION_NAME" \
            --region ${{ env.AWS_REGION }} \
            --query 'Environment.Variables' \
            --output json)
          
          # Mask sensitive values
          MASKED_ENV=$(echo "$FINAL_ENV" | jq -c '
            if .DATABASE_URL then .DATABASE_URL = (.DATABASE_URL | split("@")[0] + "@***") else . end |
            if .REDIS_AUTH_TOKEN and .REDIS_AUTH_TOKEN != "" then .REDIS_AUTH_TOKEN = "***" else . end
          ')
          echo "$MASKED_ENV" | jq '.'
          
          # Verify required variables are set
          MISSING_VARS=()
          
          if [ -z "$(echo "$FINAL_ENV" | jq -r '.DATABASE_URL // empty')" ]; then
            MISSING_VARS+=("DATABASE_URL")
          fi
          
          if [ -z "$(echo "$FINAL_ENV" | jq -r '.NODE_ENV // empty')" ]; then
            MISSING_VARS+=("NODE_ENV")
          fi
          
          if [ -z "$(echo "$FINAL_ENV" | jq -r '.STAGE // empty')" ]; then
            MISSING_VARS+=("STAGE")
          fi
          
          if [ ${#MISSING_VARS[@]} -gt 0 ]; then
            echo ""
            echo "âŒ ERROR: Required environment variables are still missing after update:"
            printf '  - %s\n' "${MISSING_VARS[@]}"
            echo ""
            echo "Please ensure these variables can be automatically retrieved or set them manually."
            exit 1
          fi
          
          echo ""
          echo "âœ… All required environment variables are set"

      - name: Lambda Deployment Summary
        run: |
          FUNCTION_NAME="${{ steps.get-lambda.outputs.lambda_function_name }}"
          
          # Get database info for summary
          DB_IDENTIFIER="${{ env.STAGE }}-flowgenie-db"
          RDS_ENDPOINT=$(aws rds describe-db-instances \
            --db-instance-identifier "$DB_IDENTIFIER" \
            --region ${{ env.AWS_REGION }} \
            --query 'DBInstances[0].Endpoint.Address' \
            --output text 2>/dev/null || echo "unknown")
          
          DB_NAME=$(aws rds describe-db-instances \
            --db-instance-identifier "$DB_IDENTIFIER" \
            --region ${{ env.AWS_REGION }} \
            --query 'DBInstances[0].DBName' \
            --output text 2>/dev/null || echo "unknown")
          
          echo "## Lambda Backend Deployment Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Stage:** ${{ env.STAGE }}" >> $GITHUB_STEP_SUMMARY
          echo "**Function Name:** $FUNCTION_NAME" >> $GITHUB_STEP_SUMMARY
          echo "**Region:** ${{ env.AWS_REGION }}" >> $GITHUB_STEP_SUMMARY
          echo "**Database:** ${DB_NAME}@${RDS_ENDPOINT}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Lambda backend has been successfully deployed!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "â„¹ï¸  Note: Database migrations run in a separate job (run-migrations)" >> $GITHUB_STEP_SUMMARY

  # Build and Deploy Worker to ECS
  # TEMPORARILY DISABLED
  deploy-worker:
    name: Build and Deploy Worker to ECS
    runs-on: ubuntu-latest
    environment: ${{ inputs.stage || 'dev' }}
    if: false  # Temporarily disabled
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Get ECR repository URI
        id: get-ecr
        run: |
          STAGE="${{ env.STAGE }}"
          REPO_NAME="${STAGE}-flowgenie-worker"
          
          # Get repository URI
          REPO_URI=$(aws ecr describe-repositories \
            --repository-names "$REPO_NAME" \
            --query 'repositories[0].repositoryUri' \
            --output text 2>/dev/null || echo "")
          
          if [ -z "$REPO_URI" ] || [ "$REPO_URI" == "None" ]; then
            echo "ERROR: ECR repository '$REPO_NAME' does not exist"
            echo "Please run infrastructure deployment first (infra-deploy workflow)"
            exit 1
          fi
          
          echo "ecr_repository=$REPO_NAME" >> $GITHUB_OUTPUT
          echo "ecr_repository_uri=$REPO_URI" >> $GITHUB_OUTPUT
          echo "ECR Repository: $REPO_URI"

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and push Docker image
        working-directory: ./backend
        env:
          IMAGE_TAG: ${{ github.sha }}
          ECR_REPOSITORY: ${{ steps.get-ecr.outputs.ecr_repository_uri }}
        run: |
          echo "Building Docker image for worker..."
          
          docker build \
            -f Dockerfile.worker \
            -t "$ECR_REPOSITORY:$IMAGE_TAG" \
            -t "$ECR_REPOSITORY:latest" \
            .
          
          echo "Pushing Docker image to ECR..."
          docker push "$ECR_REPOSITORY:$IMAGE_TAG"
          docker push "$ECR_REPOSITORY:latest"
          
          echo "Docker image pushed successfully"

      - name: Get ECS cluster and service names
        id: get-ecs
        run: |
          STAGE="${{ env.STAGE }}"
          CLUSTER_NAME="${STAGE}-flowgenie-worker"
          SERVICE_NAME="${STAGE}-flowgenie-worker"
          
          echo "ecs_cluster=$CLUSTER_NAME" >> $GITHUB_OUTPUT
          echo "ecs_service=$SERVICE_NAME" >> $GITHUB_OUTPUT
          echo "ECS Cluster: $CLUSTER_NAME"
          echo "ECS Service: $SERVICE_NAME"

      - name: Force new ECS deployment
        run: |
          CLUSTER_NAME="${{ steps.get-ecs.outputs.ecs_cluster }}"
          SERVICE_NAME="${{ steps.get-ecs.outputs.ecs_service }}"
          
          echo "Forcing new ECS deployment..."
          
          # Check if service exists
          if ! aws ecs describe-services \
            --cluster "$CLUSTER_NAME" \
            --services "$SERVICE_NAME" \
            --query 'services[0].serviceName' \
            --output text 2>&1 | grep -q "$SERVICE_NAME"; then
            echo "ERROR: ECS service '$SERVICE_NAME' does not exist"
            echo "Please run infrastructure deployment first (infra-deploy workflow)"
            exit 1
          fi
          
          # Force new deployment
          aws ecs update-service \
            --cluster "$CLUSTER_NAME" \
            --service "$SERVICE_NAME" \
            --force-new-deployment \
            --region ${{ env.AWS_REGION }}
          
          echo "ECS deployment initiated"

      - name: Wait for ECS deployment to complete
        run: |
          CLUSTER_NAME="${{ steps.get-ecs.outputs.ecs_cluster }}"
          SERVICE_NAME="${{ steps.get-ecs.outputs.ecs_service }}"
          
          echo "Waiting for ECS deployment to stabilize..."
          
          aws ecs wait services-stable \
            --cluster "$CLUSTER_NAME" \
            --services "$SERVICE_NAME" \
            --region ${{ env.AWS_REGION }}
          
          echo "ECS deployment completed successfully"

      - name: Worker Deployment Summary
        run: |
          echo "## Worker ECS Deployment Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Stage:** ${{ env.STAGE }}" >> $GITHUB_STEP_SUMMARY
          echo "**Cluster:** ${{ steps.get-ecs.outputs.ecs_cluster }}" >> $GITHUB_STEP_SUMMARY
          echo "**Service:** ${{ steps.get-ecs.outputs.ecs_service }}" >> $GITHUB_STEP_SUMMARY
          echo "**Image:** ${{ steps.get-ecr.outputs.ecr_repository_uri }}:${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Worker has been successfully deployed to ECS!" >> $GITHUB_STEP_SUMMARY

  # Verify Redis Cache
  # TEMPORARILY DISABLED
  verify-redis:
    name: Verify Redis Cache Infrastructure
    runs-on: ubuntu-latest
    environment: ${{ inputs.stage || 'dev' }}
    if: false  # Temporarily disabled
    
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Verify Redis cluster exists
        run: |
          STAGE="${{ env.STAGE }}"
          REPLICATION_GROUP_ID="${STAGE}-flowgenie-redis"
          
          echo "Verifying Redis cluster: $REPLICATION_GROUP_ID"
          
          REDIS_STATUS=$(aws elasticache describe-replication-groups \
            --replication-group-id "$REPLICATION_GROUP_ID" \
            --query 'ReplicationGroups[0].Status' \
            --output text 2>&1 || echo "NOT_FOUND")
          
          if [ "$REDIS_STATUS" == "NOT_FOUND" ] || [ -z "$REDIS_STATUS" ] || [ "$REDIS_STATUS" == "None" ]; then
            echo "ERROR: Redis cluster '$REPLICATION_GROUP_ID' does not exist"
            echo "Please run infrastructure deployment first (infra-deploy workflow)"
            exit 1
          fi
          
          echo "Redis cluster status: $REDIS_STATUS"
          
          if [ "$REDIS_STATUS" != "available" ]; then
            echo "WARNING: Redis cluster is not in 'available' state"
            echo "Current status: $REDIS_STATUS"
          else
            echo "Redis cluster is available"
          fi

      - name: Redis Verification Summary
        run: |
          echo "## Redis Cache Verification Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Stage:** ${{ env.STAGE }}" >> $GITHUB_STEP_SUMMARY
          echo "**Redis Cluster:** ${{ env.STAGE }}-flowgenie-redis" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Redis cache infrastructure verified!" >> $GITHUB_STEP_SUMMARY
